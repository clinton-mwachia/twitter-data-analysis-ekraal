---
title: "Tweeter Data Analysis"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
---

```{r setup, include=FALSE}
library(flexdashboard)
library(rtweet)
library(ggplot2)
library(dplyr)
library(tidytext)
library(wordcloud)
library(tidyr)
library(reshape2)
library(wordcloud)
library(scales)
library(gt)

crypto_tweets = search_tweets(q='#cryptocurrencies', n=2000, include_rts = FALSE)

crypto_users = search_users(q='#cryptocurrencies', n = 1000)

## Function to plot the users
plot_users = function(data){
  data %>%
    count(location, sort = TRUE) %>%
    mutate(location = reorder(location, n)) %>%
    mutate(prop = n/sum(n)) %>%
    top_n(20) %>%
    ggplot(aes(x = location, y = n)) +
    geom_text(aes(label = percent(prop)),  hjust = -1) +
    geom_col(fill='blue') +
    coord_flip() + 
    labs(x = "Users Location", y = "Count",
         title = "Users data (top 20 rows) on hashtag: Cryptocurrencies",
         subtitle = 'CRYPTOCURRENCIES')
  
}
plot_users(crypto_users)

### PICKING THE COLUMNS AM INTERESTED IN MY ANALYSIS
crypto_dataframe= data.frame(
  time_sent = crypto_tweets$created_at,
  screen_name = crypto_tweets$screen_name,
  tweet = crypto_tweets$text
)

#### CLEANING THE TWEETS
### PROCESSING THETWEETS
## removing links and stop words
crypto_dataframe$tweet = gsub(" ?(f|ht)tp(s?)://(.*)[.][a-z]+", "", crypto_dataframe$tweet)
head(crypto_dataframe, 4)

crypto_clean_tweets = crypto_dataframe %>%
  select(tweet)  %>%
  unnest_tokens(word, tweet)

head(crypto_clean_tweets, 10)

### REMOVING STOP WORDS
crypto_clean_tweets = crypto_clean_tweets %>% 
  anti_join(stop_words) %>%
  filter(!word == "rt")

plot_tweets = function(tweets){
  tweets %>%
    count(word, sort = TRUE) %>%
    mutate(word = reorder(word, n)) %>%
    mutate(prop = n/sum(n)) %>%
    top_n(30) %>%
    ggplot(aes(x = word, y = n)) +
    geom_text(aes(label = percent(prop)),  hjust = -1) +
    geom_col(fill='blue') +
    coord_flip() + 
    labs(x = "Crypto words", y = "Count",
         title = "Word Count",
         subtitle = 'CRYPTOCURRENCIES')
  
}

crypto_tweets_paired = crypto_dataframe %>%
  select(tweet) %>%
  unnest_tokens(paired_words, tweet, token = "ngrams", n = 2) %>%
  count(paired_words, sort = TRUE)

sentiment_crypto_counts = crypto_clean_tweets %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

start = min(crypto_tweets$created_at)
start
stop = max(crypto_tweets$created_at)
stop
```

Column {data-width=400}
-----------------------------------------------------------------------

### WordCloud

```{r}
crypto_clean_tweets %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  acast(word ~ sentiment, value.var = "n", fill = 0) %>%
  comparison.cloud(colors = c("gray", "blue"),
                   max.words = 100)
```

Column {data-width=500}
-----------------------------------------------------------------------

### Sentimental Analysis

```{r}
sentiment_crypto_counts %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  mutate(prop = n/sum(n)) %>%
  ggplot(aes(word,n, fill = sentiment)) +
  geom_text(aes(label = percent(prop)),  hjust = 0.01) +
  geom_col(show.legend = TRUE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(title = "Response of users on cryptocurrencies",
       y = "Contribution to sentiment",
       x = NULL) +
  coord_flip()

```

### Users and Most Frequent words Used

```{r}
plot_users(crypto_users)

plot_tweets(crypto_clean_tweets)
```

